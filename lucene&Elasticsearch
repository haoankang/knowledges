1. 分词算法概述.
  a. 英文分词原理：
     输入文本、词汇分割、词汇过滤（去除停留词）、词干提取（形态还原）、大写转小写、结果输出；
  b. 中文分词原理：
     比较复杂，主要是因为中文的词与词之间不像英文用空格隔开。中文分词主要有三种方法：
     词典匹配分词法、语义理解分词法、词频统计分词法.
2. lucene架构.
   a. 检索流程：查询分析、分词技术、关键词检索、搜索排序.
3. 简介.
   lucene是一个开源的全文检索引擎工具包；
   Luke是一个用来查看lucene、solr、Elasticsearch索引的开源GUI工具；
   IK分词器是一个开源的、基于Java语言开发的轻量级中文分词工具包；
